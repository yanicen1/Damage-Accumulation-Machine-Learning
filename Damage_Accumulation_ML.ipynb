{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5a98f87",
   "metadata": {},
   "source": [
    "## Damage Prediction in Materials with Machine Learning: Decision Tree, Random Forest, and Gradient Boosting Algorithms\n",
    "\n",
    "First, import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f4920753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrames and Arrays\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data visualisation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_regression # Mutual Information regression for feature selection\n",
    "from sklearn.model_selection import train_test_split # Function to split data into training and testing sets\n",
    "from sklearn.model_selection import cross_val_score # Function for evaluating a model using cross-validation\n",
    "from sklearn.model_selection import GridSearchCV # finding the optimal hyperparameters for a machine learning model\n",
    "\n",
    "# Algorithms for regression tasks\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree # Decision Tree algorithm and tree plotting\n",
    "from sklearn.ensemble import RandomForestRegressor # Random Forest algorithm\n",
    "from xgboost import XGBRegressor # XGBoost algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168880d1",
   "metadata": {},
   "source": [
    "Next, load the required 'CSV' files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6480e2ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nor_oper_time</th>\n",
       "      <th>Damage</th>\n",
       "      <th>Load_type</th>\n",
       "      <th>Material</th>\n",
       "      <th>Imp_J</th>\n",
       "      <th>Warp</th>\n",
       "      <th>Circ_lack_gl</th>\n",
       "      <th>Sq_lack_gl</th>\n",
       "      <th>Indent_kN</th>\n",
       "      <th>Lay_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.12</td>\n",
       "      <td>1.640000e-08</td>\n",
       "      <td>Interlam_sh</td>\n",
       "      <td>CFL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Nor_oper_time        Damage    Load_type Material  Imp_J  Warp  \\\n",
       "0           0.12  1.640000e-08  Interlam_sh      CFL      0     0   \n",
       "\n",
       "   Circ_lack_gl  Sq_lack_gl  Indent_kN  Lay_col  \n",
       "0             0           0          0        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the required 'CSV' file\n",
    "df_init = pd.read_csv('df.csv')\n",
    "df_init.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1b11a3",
   "metadata": {},
   "source": [
    "The DataFrame displayed above contains several important columns, including Operating Time, Damage, Load, Material, and Defect Types, among others. Notably, it also contains two columns with categorical values: `Load_type` and `Material`. These categorical variables need to be transformed into numerical format to enable their use in machine learning models, which typically require numerical input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "253aa951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nor_oper_time</th>\n",
       "      <th>Damage</th>\n",
       "      <th>Imp_J</th>\n",
       "      <th>Warp</th>\n",
       "      <th>Circ_lack_gl</th>\n",
       "      <th>Sq_lack_gl</th>\n",
       "      <th>Indent_kN</th>\n",
       "      <th>Lay_col</th>\n",
       "      <th>Load_type_Compr</th>\n",
       "      <th>Load_type_Interlam_sh</th>\n",
       "      <th>Load_type_Ios_sh</th>\n",
       "      <th>Load_type_Sh</th>\n",
       "      <th>Load_type_Tens</th>\n",
       "      <th>Material_CFL</th>\n",
       "      <th>Material_ST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.12</td>\n",
       "      <td>1.640000e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Nor_oper_time        Damage  Imp_J  Warp  Circ_lack_gl  Sq_lack_gl  \\\n",
       "0           0.12  1.640000e-08      0     0             0           0   \n",
       "\n",
       "   Indent_kN  Lay_col  Load_type_Compr  Load_type_Interlam_sh  \\\n",
       "0          0        0                0                      1   \n",
       "\n",
       "   Load_type_Ios_sh  Load_type_Sh  Load_type_Tens  Material_CFL  Material_ST  \n",
       "0                 0             0               0             1            0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert all categorical variables in the DataFrame to dummy/indicator variables\n",
    "# This process creates binary columns for each category of every categorical variable\n",
    "df_init = pd.get_dummies(df_init, drop_first=False).copy()\n",
    "df_init.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af3cf76",
   "metadata": {},
   "source": [
    "Identify missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "030f6833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nor_oper_time            0\n",
       "Damage                   0\n",
       "Imp_J                    0\n",
       "Warp                     0\n",
       "Circ_lack_gl             0\n",
       "Sq_lack_gl               0\n",
       "Indent_kN                0\n",
       "Lay_col                  0\n",
       "Load_type_Compr          0\n",
       "Load_type_Interlam_sh    0\n",
       "Load_type_Ios_sh         0\n",
       "Load_type_Sh             0\n",
       "Load_type_Tens           0\n",
       "Material_CFL             0\n",
       "Material_ST              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values in the DataFrame\n",
    "df_init.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deb552b",
   "metadata": {},
   "source": [
    "There are no missing values.\n",
    "\n",
    "Next, let's split the dataset into features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21418761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the features and labels for model training\n",
    "X = df_init.copy() # Features\n",
    "y = X.pop(\"Damage\") # Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b813dd9",
   "metadata": {},
   "source": [
    "Next, let's examine which features have the most significant impact on the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dfe9906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MI sc. import. in %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nor_oper_time</th>\n",
       "      <td>30.194943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Material_CFL</th>\n",
       "      <td>12.516065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Material_ST</th>\n",
       "      <td>12.419923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Load_type_Tens</th>\n",
       "      <td>11.231161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indent_kN</th>\n",
       "      <td>6.225634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Load_type_Sh</th>\n",
       "      <td>5.472431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Imp_J</th>\n",
       "      <td>5.418548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Load_type_Interlam_sh</th>\n",
       "      <td>5.218290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Load_type_Compr</th>\n",
       "      <td>2.989878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sq_lack_gl</th>\n",
       "      <td>2.703120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Circ_lack_gl</th>\n",
       "      <td>2.224271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lay_col</th>\n",
       "      <td>1.973776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Warp</th>\n",
       "      <td>0.928444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Load_type_Ios_sh</th>\n",
       "      <td>0.483517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       MI sc. import. in %\n",
       "Nor_oper_time                    30.194943\n",
       "Material_CFL                     12.516065\n",
       "Material_ST                      12.419923\n",
       "Load_type_Tens                   11.231161\n",
       "Indent_kN                         6.225634\n",
       "Load_type_Sh                      5.472431\n",
       "Imp_J                             5.418548\n",
       "Load_type_Interlam_sh             5.218290\n",
       "Load_type_Compr                   2.989878\n",
       "Sq_lack_gl                        2.703120\n",
       "Circ_lack_gl                      2.224271\n",
       "Lay_col                           1.973776\n",
       "Warp                              0.928444\n",
       "Load_type_Ios_sh                  0.483517"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mi_scor(X, y):\n",
    "    \"\"\"\n",
    "    Calculate mutual information scores between each feature and the target variable,\n",
    "    and return the scores as percentages of the total importance.\n",
    "    \n",
    "    Parameters:\n",
    "    X (pd.DataFrame): Features dataset\n",
    "    y (pd.Series): Target variable\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with features as index and their mutual information scores as percentages\n",
    "    \"\"\"\n",
    "    mi_sc = mutual_info_regression(X, y) # Compute mutual information scores between each feature and the target variable\n",
    "    mi_sc = pd.DataFrame(mi_sc, columns=[\"MI sc. import. in %\"], index=X.columns) # Convert mutual inform. into a DataFrame\n",
    "    mi_sc = mi_sc.sort_values(by=\"MI sc. import. in %\", ascending=False) # Sort the DataFrame by mutual information\n",
    "    \n",
    "    return mi_sc/mi_sc.sum()*100 # Convert the mutual information scores to percentages of the total importance\n",
    "\n",
    "mi_scor(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55216d11",
   "metadata": {},
   "source": [
    "Notably, the variables `Nor_oper_time`, `Material_CFL`, `Material_ST` and `Load_type_Tens` have the greatest impact, collectively accounting for approximately 65% of the total importance.\n",
    "\n",
    "Then, let's divide the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03ff947c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f43d565",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "\n",
    "With our dataset prepared for training and testing, we can move forward with applying machine learning algorithms. The Decision Tree algorithm is one of the simplest and most intuitive models, utilizing a tree-like structure where each internal node represents a decision based on a feature. It partitions the data into subsets, leading to outcomes at the leaf nodes, ultimately aiming to make accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cf3135b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 11, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "Best cross-validation MSE: 0.00147\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Decision Tree Regressor\n",
    "dt_regressor = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid_DT = {\n",
    "    'max_depth': [None, 10, 11, 15, 16, 17, 18, 19, 20], # Depth of the tree\n",
    "    'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10], # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with the Decision Tree Regressor\n",
    "# cv=5 specifies 5-fold cross-validation\n",
    "# scoring='neg_mean_squared_error' means the minimization of the mean squared error\n",
    "grid_search_DT = GridSearchCV(dt_regressor, param_grid_DT, cv=5, scoring='neg_mean_squared_error')\n",
    "# Fit GridSearchCV to the training data\n",
    "grid_search_DT.fit(X_train, y_train) \n",
    "\n",
    "# Display the best parameters and the best cross-validation mean squared error (MSE)\n",
    "print(\"Best parameters:\", grid_search_DT.best_params_)\n",
    "print(\"Best cross-validation MSE: {:.5f}\".format(-grid_search_DT.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae95c2a0",
   "metadata": {},
   "source": [
    "The code above performs hyperparameter tuning for a Decision Tree Regressor to find the optimal combination of parameters that minimizes the mean squared error (MSE) through 5-fold cross-validation. With these best parameters, we can apply the Decision Tree model and evaluate its performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffc341d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: R² score on the test set: 0.919\n",
      "Decision Tree: MSE on the test set: 0.00166\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the final model on the test set\n",
    "DT_final_model = grid_search_DT.best_estimator_ # Retrieve the best estimator\n",
    "DT_final_model.fit(X_train, y_train)  # Fit the final model to the entire training set using the best parameters\n",
    "\n",
    "# Evaluate the model's performance on the test set using the coefficient of determination (R² score)\n",
    "test_CoD = DT_final_model.score(X_test, y_test)  \n",
    "# Generate predictions on the test set\n",
    "y_pr = DT_final_model.predict(X_test)\n",
    "\n",
    "# Print the coefficient of determination and the mean squared error\n",
    "print(\"Decision Tree: R² score on the test set: {:.3f}\".format(test_CoD))\n",
    "print(\"Decision Tree: MSE on the test set: {:.5f}\".format(((y_test - y_pr)**2).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d713b1",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "The next algorithm we'll explore is the Random Forest Regressor, which is an ensemble method known for its ability to improve prediction accuracy by combining multiple decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8ea031a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2000 candidates, totalling 10000 fits\n",
      "Best parameters: {'max_depth': 10, 'max_features': 0.8, 'min_samples_leaf': 3, 'min_samples_split': 10, 'n_estimators': 150}\n",
      "Best cross-validation MSE: 0.00123\n"
     ]
    }
   ],
   "source": [
    "# Initialize the RandomForestRegressor\n",
    "RF_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# This grid specifies the hyperparameters to be tuned for the RandomForestRegressor\n",
    "param_grid_RF = {\n",
    "    'n_estimators': [100, 150, 200, 250, 300], # Number of trees in the forest\n",
    "    'max_features': [0.2, 0.4, 0.6, 0.8, 1], # Fraction of features to consider for each split\n",
    "    'max_depth': [None, 5, 10, 15, 20], # Maximum depth of the trees\n",
    "    'min_samples_split': [2, 5, 10, 15], # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 3, 4] # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "# Setup GridSearchCV with the RandomForestRegressor and the parameter grid\n",
    "grid_search_RF = GridSearchCV(estimator=RF_model, param_grid=param_grid_RF, cv=5, scoring='neg_mean_squared_error', \n",
    "                           verbose=2, n_jobs=-1)\n",
    "# Fit GridSearchCV on the training data\n",
    "grid_search_RF.fit(X_train, y_train)\n",
    "    \n",
    "# Retrieve the best parameters and the best cross-validation mean squared error\n",
    "print(\"Best parameters:\", grid_search_RF.best_params_)\n",
    "print(\"Best cross-validation MSE: {:.5f}\".format(-grid_search_RF.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1cf0918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: R² score on the test set: 0.935\n",
      "Decision Tree: MSE on the test set: 0.00133\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the final model on the test set\n",
    "RF_final_model = grid_search_RF.best_estimator_ # Retrieve the best estimator\n",
    "RF_final_model.fit(X_train, y_train)  # Fit the final model to the entire training set using the best parameters\n",
    "\n",
    "# Evaluate the model's performance on the test set using the coefficient of determination (R² score)\n",
    "test_CoD = RF_final_model.score(X_test, y_test)\n",
    "# Generate predictions on the test set\n",
    "y_pr = RF_final_model.predict(X_test)\n",
    "\n",
    "# Print the coefficient of determination and the mean squared error\n",
    "print(\"Decision Tree: R² score on the test set: {:.3f}\".format(test_CoD))\n",
    "print(\"Decision Tree: MSE on the test set: {:.5f}\".format(((y_test - y_pr)**2).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cb5ff8",
   "metadata": {},
   "source": [
    "### Gradient Boosting\n",
    "\n",
    "The last algorithm we'll explore is Gradient Boosting, which is an ensemble technique that builds models sequentially. Each new model corrects the errors of the previous ones by focusing on the residuals, or mistakes, made by the prior models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "004dc04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 405 candidates, totalling 2025 fits\n",
      "Best parameters: {'colsample_bytree': 0.94, 'learning_rate': 0.17, 'max_depth': 4, 'n_estimators': 50, 'subsample': 1.0}\n",
      "Best cross-validation MSE: 0.00265\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for XGBRegressor\n",
    "param_grid_XGB = {\n",
    "    'n_estimators': [10, 50, 100], # Number of boosting rounds to build\n",
    "    'learning_rate': [0.15, 0.17, 0.19], # Step size shrinkage used to prevent overfitting\n",
    "    'max_depth': [1, 3, 4, 5, 8], # Maximum depth of the individual trees\n",
    "    'colsample_bytree': [0.90, 0.92, 0.94], # Fraction of features to be used for each tree\n",
    "    'subsample': [0.96, 0.98, 1.0] # Fraction of samples used for fitting each tree\n",
    "}\n",
    "\n",
    "# Initialize the XGBRegressor\n",
    "xgb = XGBRegressor(random_state=42)\n",
    "\n",
    "# Setup GridSearchCV with the XGBRegressor and the parameter grid\n",
    "grid_search_XGB = GridSearchCV(estimator=xgb, param_grid=param_grid_XGB, cv=5, scoring='neg_mean_squared_error', \n",
    "                               verbose=2, n_jobs=-1)\n",
    "\n",
    "# Perform the grid search to find the best hyperparameters\n",
    "grid_search_XGB.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the best parameters and the best cross-validation mean squared error\n",
    "print(\"Best parameters:\", grid_search_XGB.best_params_)\n",
    "print(\"Best cross-validation MSE: {:.5f}\".format(-grid_search_XGB.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "328b7af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: R² score on the test set: 0.846\n",
      "Decision Tree: MSE on the test set: 0.00315\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the final model on the test set\n",
    "XGB_final_model = grid_search_XGB.best_estimator_ # Retrieve the best estimator\n",
    "XGB_final_model.fit(X_train, y_train)  # Fit the final model to the entire training set using the best parameters\n",
    "\n",
    "# Evaluate the model's performance on the test set using the coefficient of determination (R² score)\n",
    "test_CoD = XGB_final_model.score(X_test, y_test)\n",
    "# Generate predictions on the test set\n",
    "y_pr = XGB_final_model.predict(X_test)\n",
    "\n",
    "# Print the coefficient of determination and the mean squared error\n",
    "print(\"Decision Tree: R² score on the test set: {:.3f}\".format(test_CoD))\n",
    "print(\"Decision Tree: MSE on the test set: {:.5f}\".format(((y_test - y_pr)**2).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d758e2",
   "metadata": {},
   "source": [
    "Comparative analysis of algorithms shows that the Random Forest algorithm demonstrates the highest descriptive capability in modeling the patterns of damage accumulation and is preferred for use in this case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
